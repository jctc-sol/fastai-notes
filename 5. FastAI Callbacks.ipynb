{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "- the goal of callbacks in FastAI is to **allow the training loop to be highly customizable** \n",
    "- this is accomplished by injecting conditions such as `on_batch_begin`, `on_batch_end`, `on_epoch_begin`, `on_epoch_end` etc that trigger corresponding custom callback functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Mini-Batch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    learn.model.train() # set to training mode\n",
    "    for xb,yb in learn.data.train_dl: # grabs mini-batch from dataloader\n",
    "        loss = learn.loss_func(learn.model(xb), yb) # compute loss\n",
    "        loss.backward()  # compute gradients\n",
    "        learn.opt.step() # update parameters\n",
    "        learn.opt.zero_grad() # reset gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"infinitely customizable\" training loop\n",
    "\n",
    "The code snippet below demonstrates the scafold of a training loop that allows a wide variety of customizability based on callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks.on_train_begin()\n",
    "for _ in range(epoch):\n",
    "    callbacks.on_epoch_begin()  #---------------callback before an epoch begins\n",
    "    learn.model.train()\n",
    "    for xb,yb in learn.data.train_dl:\n",
    "        callbacks.on_batch_begin() #------------callback before a batch begins\n",
    "        y = model(xb)\n",
    "        callbacks.on_loss_begin()  #------------callback before loss computation begins\n",
    "        loss = loss_func(y, yb)\n",
    "        callbacks.on_backward_begin() #---------callback before gradient computation begin\n",
    "        loss.backward() # backward pass\n",
    "        callbacks.on_backward_end()  #----------callback after gradient computation begin\n",
    "        opt.step()\n",
    "        callbacks.on_step_end() #---------------callback after param update begins\n",
    "        opt.zero_grad() \n",
    "        callbacks.on_batch_end() #--------------callback after a batch\n",
    "    callbacks.on_epoch_end() #------------------callback after an epoch\n",
    "callbacks.on_train_end() #----------------------callback after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback class\n",
    "\n",
    "- to provide the generic functionality of all the callbacks listed in the training loop above, it is convenient to define a `Callback` class template.\n",
    "- all existing and new custom callbacks to be implemented need to inherit from this base class\n",
    "\n",
    "The toy-version of the `Callback` class is provided below, for detail of the actual `Callback` class, see: https://docs.fast.ai/callback.html#Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely associated with the `Callback` class is the `CallbackHandler` class, which combines all the callbacks together and call any relevant callback functions for each training stage. See: https://docs.fast.ai/callback.html#CallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,cbs=None):\n",
    "        self.cbs = cbs if cbs else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
    "        return res\n",
    "\n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        res = self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_step()\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learn.stop\n",
    "        finally: self.learn.stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is roughly how FastAI v1.0 implements it. But looking at the code, there's still quite a bit of repetition with all the:\n",
    "\n",
    "`res = condition\n",
    "for cb in self.cbs: res = res and cb._method_()\n",
    "return res`\n",
    "\n",
    "The new `Runner` class appears to be how future versions of FastAI will be implemented at the time of writing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
